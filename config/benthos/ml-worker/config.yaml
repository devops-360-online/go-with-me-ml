input:
  amqp_0_9:
    url: ${RABBITMQ_URL:amqp://guest:guest@localhost:5672/}
    queue: inference_requests
    consumer_tag: ml_worker
    prefetch_count: 1
    prefetch_size: 0

pipeline:
  processors:
    # Update request status to processing
    - bloblang: |
        root = this
        root.status = "processing"
    
    # Update request status in PostgreSQL
    - processor: sql_update_request_status
    
    # Log that request is being processed
    - processor: log_request_processing
    
    # Call ML service
    - http:
        url: ${ML_SERVICE_URL:http://localhost:8000/generate}
        verb: POST
        headers:
          Content-Type: application/json
        timeout: 60s
    
    # Calculate actual token usage
    - bloblang: |
        root = this
        root.actualTokens = this.total_tokens
        root.tokenAdjustment = this.total_tokens - this.estimatedTokens
    
    # Adjust token count in Redis
    - processor: redis_adjust_tokens
    
    # Log token usage
    - processor: log_token_usage
    
    # Store result in PostgreSQL
    - processor: sql_store_result
    
    # Log request completion
    - processor: log_request_completed

output:
  amqp_0_9:
    url: ${RABBITMQ_URL:amqp://guest:guest@localhost:5672/}
    exchange: ""
    key: inference_results
    persistent: true
    max_in_flight: 10

metrics: ${metrics_config}
logger: ${logger_config}

resources:
  - label: sql_update_request_status
    path: /benthos/common/sql.yaml
  - label: sql_store_result
    path: /benthos/common/sql.yaml
  - label: redis_adjust_tokens
    path: /benthos/common/redis.yaml
  - label: log_request_processing
    path: /benthos/common/observability.yaml
  - label: log_token_usage
    path: /benthos/common/observability.yaml
  - label: log_request_completed
    path: /benthos/common/observability.yaml
  - label: metrics_config
    path: /benthos/common/observability.yaml
  - label: logger_config
    path: /benthos/common/observability.yaml 